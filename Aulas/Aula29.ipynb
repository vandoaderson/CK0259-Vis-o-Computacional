{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 29 – Arquiteturas de Redes Neurais Convolucionais\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "Como discutido na Aula 26, existem diferentes arquiteturas de RNC que tentam otimizar o processo de classificação. Esta aula tem o objetivo de citar algumas das principais e comentar as ideias por trás delas, sem a intenção de aprofundamento, pois o assunto é muito extenso e complexo, cabendo inclusive uma disciplina específica para isso.\n",
    "\n",
    "Como já falado, as RNC não são criação recente, tendo a ideia geral de utilizar neurônios como filtros para extrair características de imagens sido colocada ainda nos anos 80. Entretanto, a disponibilidade de poder de processamento e armazenamento de dados permitiu um grande crescimento da área nos anos 2010, identificando-se aí o que é chamado de Deep Learning, pois tratam de redes com muitas camadas (profundas).\n",
    "\n",
    "Até 2011, competição ImageNet Large Scale Visual Recognition Challenge (ILSVRC) tinha como vencedores as chamadas redes neurais rasas (ImageNet é um conjunto de dados marcados e classificados para diversos objetos). A partir de 2012 começaram a ser introduzidas redes que podiam ser chamadas de profundas e a performance em relação a 2011 da rede vencedora melhorou em 37% (sendo que 2011 e 2010 a performance foi praticamente a mesma).\n",
    "\n",
    "A vencedora em 2011 foi a AlexNet, basicamente trazia a estrutura de RNC já discutida na aula 26, mas com 8 camadas que, apesar de parecer pouco, já é bastante pesado computacionalmente e só obteve sucesso graças à implementação usando GPU. Melhoras em sua implementação permitiram um resultado melhorado e novamente ganhou o desafio de 2013 (essa implementação é conhecida como ZFNet e tem melhores ajustes de hiperparâmetros, como quantidade, tamanho e deslocamento dos filtros).\n",
    "\n",
    "Em 2014 a arquitetura vencedora em localização foi a VGG (mas não em classificação), com 19 camadas e performance 38% melhor em relação à ZFNet. A VGG possuía filtros ainda menores (convoluções 3x3) com deslocamento unitário. Tais filtros menores exigiam mais camadas. Uma camada de convolução 7x7 corresponde a três camadas de convolução 3x3.\n",
    "\n",
    "A vencedora em classificação em 2014 foi a GoogLeNet, com 22 camadas, com melhora de 8% em relação à VGG e 43% em relação à ZFNet. A GoogLeNet trouxe de novidade a criação de módulos, chamados “Inception”, que aplica filtros em paralelo e depois concatena o resultado. Isso aumentou consideravelmente a complexidade de cada camada, mas também melhorou a eficiência da extração de características. Para ajudar no treinamento, classificações são feitas nas camadas intermediárias para melhorar a eficiência do ajuste de parâmetros, pois a correção baseada apenas na saída final da rede seria ineficiente com tantas camadas e de alta complexidade.\n",
    "\n",
    "Em 2015 houve uma “revolução de profundidade” com a vencedora ResNet. Com 152 camadas, conseguiu um resultado ainda 47% melhor em relação à já excelente GoogLeNet. Para trabalhar com tantas camadas, a rede introduz a ideia de “conexões residuais”. Treinar uma rede muito profunda é um problema de otimização pesado, pois o número de parâmetros a ajustar cresce muito. A ResNet trabalha com a hipótese de que treinar parâmetros (camadas) de “resíduo” da imagem é mais eficiente que treinar para a imagem original. Então “bloco residual” para frente exatamente seus valores de entrada e, na saída, soma-se a entrada que “saltou” à saída filtrada. Ou seja, o ajuste que deve ser feito nos filtros é apenas para adequar a diferença entre a saída e a entrada do bloco. Isso de fato se mostrou mais eficiente no treinamento, permitindo aumentar o número de camadas e, consequentemente, a performance de detecção da rede.\n",
    "\n",
    "Em 2017 (último campeonato realizado), a vencedora aplicou a ideia da ResNet para treinar uma rede com blocos residuais formados por camadas de módulos Inceptions, resultando na Inception-v4 (outras vieram ainda antes).\n",
    "\n",
    "## 2. Material Complementar\n",
    "\n",
    "http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf\n",
    "\n",
    "https://www.youtube.com/watch?v=DAOcjicFr1Y\n",
    "\n",
    "http://www.image-net.org/\n",
    "\n",
    "## 3. Exercícios\n",
    "\n",
    "1. Keras é uma API Python para Deep Learning. Construir redes neurais convolucionais utilizando essa API é basicamente um processo de empilhar camadas através de chamadas de funções. Realize o seguinte tutorial para construir uma rede simples para classificação de caracteres: https://keras.io/examples/vision/mnist_convnet/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "422/422 [==============================] - 90s 212ms/step - loss: 0.3667 - accuracy: 0.8897 - val_loss: 0.0828 - val_accuracy: 0.9785\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 88s 208ms/step - loss: 0.1128 - accuracy: 0.9664 - val_loss: 0.0612 - val_accuracy: 0.9832\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 88s 208ms/step - loss: 0.0827 - accuracy: 0.9745 - val_loss: 0.0445 - val_accuracy: 0.9878\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 88s 209ms/step - loss: 0.0709 - accuracy: 0.9787 - val_loss: 0.0455 - val_accuracy: 0.9868\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 89s 210ms/step - loss: 0.0621 - accuracy: 0.9803 - val_loss: 0.0389 - val_accuracy: 0.9900\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 89s 210ms/step - loss: 0.0553 - accuracy: 0.9830 - val_loss: 0.0344 - val_accuracy: 0.9910\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 88s 208ms/step - loss: 0.0497 - accuracy: 0.9842 - val_loss: 0.0332 - val_accuracy: 0.9910\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 99s 234ms/step - loss: 0.0479 - accuracy: 0.9850 - val_loss: 0.0321 - val_accuracy: 0.9913\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 100s 238ms/step - loss: 0.0442 - accuracy: 0.9859 - val_loss: 0.0333 - val_accuracy: 0.9915\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 95s 225ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.0294 - val_accuracy: 0.9928\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 96s 228ms/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.0293 - val_accuracy: 0.9917\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 95s 226ms/step - loss: 0.0361 - accuracy: 0.9885 - val_loss: 0.0340 - val_accuracy: 0.9912\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 91s 216ms/step - loss: 0.0367 - accuracy: 0.9880 - val_loss: 0.0286 - val_accuracy: 0.9927\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 95s 226ms/step - loss: 0.0340 - accuracy: 0.9889 - val_loss: 0.0279 - val_accuracy: 0.9933\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 102s 243ms/step - loss: 0.0318 - accuracy: 0.9898 - val_loss: 0.0293 - val_accuracy: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f87039dc1c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.025909854099154472\n",
      "Test accuracy: 0.9919000267982483\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
