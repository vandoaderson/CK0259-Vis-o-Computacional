{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 20 – Classificadores Bayesianos\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "Como começamos a discutir na aula passada, o processo de identificação de uma imagem trata de atribuir uma classificação para o “dado” imagem após pré-processamento e redução de dimensionalidade. O algoritmo K-NN atribui um dado a uma classe pela semelhança (proximidade) entre o dado a classificar e dados pré-classificados. Esse método, entretanto, não dá a certeza de que a classificação será correta nem informa sua probabilidade de estar correto.\n",
    "\n",
    "Métodos estatísticos classificam o dado informando as probabilidades de classes para os dados. Já que dados de uma mesma classe não são necessariamente iguais, ter o nível de incerteza para a classificação é importante. A maioria dos métodos de visão computacional, portanto, trabalham exatamente dessa forma, calculando estatisticamente a classificação de um dado.\n",
    "\n",
    "No caso dos classificadores Bayesianos, queremos saber a probabilidade de estarmos diante de  uma determinada classe, dada a imagem (na verdade, o dado tratado que representa a imagem). Ou seja, é o cálculo de uma probabilidade condicional seguindo o teorema de Bayes.\n",
    "\n",
    "Se Ci é uma classe e X é o dado que representa a imagem, temos:\n",
    "\n",
    "## P(Ci | X) = P(Ci)*P( X | Ci) / P(X),\n",
    "\n",
    "ou seja, a probabilidade de termos a classe i (por exemplo, termos um gato) dado X (representação da imagem após pré-processamento e redução de dimensionalidade) é igual à probabilidade da classe Ci (probabilidade de um gato aparecer em qualquer imagem) vezes a probabilidade do dado X aparecer dada a classe Ci (a probabilidade daquele tipo de dado aparecer entre todas as imagens de gato) dividido pela probabilidade do dado X aparecer entre todas as imagens possíveis.\n",
    "\n",
    "O grande problema para conseguir computar a função acima é conhecer essas probabilidades. Quantas imagens existem? Quantas imagens são de gato? Qual a probabilidade uma determinada imagem aparecer? O cálculo, portanto, é feito assumindo-se algumas condições iniciais, como, por exemplo, uma distribuição normal das imagens e os parâmetros vão sendo ajustados iterativamente, de acordo com os erros e acertos do classificador (quanto mais imagens ele for vendo, mais precisas vão sendo as estimativas das probabilidades). \n",
    "\n",
    "Para mais detalhes sobre a implementação do treinamento desse e outros classificadores, sugiro cursar a disciplina de Aprendizagem de Máquina. De fato, a partir de agora, a disciplina de Visão Computacional, que até então tratava da aplicação dos métodos de Processamento de Imagens, passa a tratar da aplicação dos métodos de Aprendizagem de Máquina.\n",
    "\n",
    "## 2. Leitura Complementar\n",
    "\n",
    "Livro E – Seção 11.4 \n",
    "\n",
    "Livro 1 – Seção 9.2\n",
    "\n",
    "Livro 3 – Seção 12.2.2\n",
    "\n",
    "## 3. Exercícios\n",
    "\n",
    "1. Baixe umas imagens de gatos e de cachorros no Google e treine um classificador Bayesiano em OpenCV (faça o treinamento com as imagens pré-processadas e com dimensionalidade reduzida, como no K-NN). A biblioteca já traz implementado o classificador. Feito isso, procure novas imagens diferentes das que você utilizou no treino e teste seu classificador. Qual taxa de acerto você obteve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def prepare_dataset(train_dir, val_dir, size):\n",
    "  \n",
    "  # training set\n",
    "  \n",
    "  directory = os.listdir(train_dir + '/Dog')\n",
    "  train_dogs = []\n",
    "  train_dogs_labels = []\n",
    "  for img in directory:\n",
    "    train_dogs.append(cv2.resize(cv2.imread(train_dir + '/Dog/' + img), (size, size)).reshape(-1))\n",
    "    train_dogs_labels.append(1)\n",
    "    \n",
    "  train_dogs = np.array(train_dogs)\n",
    "  train_dogs_labels = np.array(train_dogs_labels)\n",
    "  directory = os.listdir(train_dir + '/Cat')\n",
    "  train_cats = []\n",
    "  train_cats_labels = []\n",
    "  for img in directory:\n",
    "    train_cats.append(cv2.resize(cv2.imread(train_dir + '/Cat/' + img), (size, size)).reshape(-1))\n",
    "    train_cats_labels.append(0)\n",
    "\n",
    "  train_cats = np.array(train_cats)\n",
    "  train_cats_labels = np.array(train_cats_labels)\n",
    "  \n",
    "  # validation set\n",
    "  \n",
    "  directory = os.listdir(val_dir + '/Dog')\n",
    "  val_dogs = []\n",
    "  val_dogs_labels = []\n",
    "  for img in directory:\n",
    "    val_dogs.append(cv2.resize(cv2.imread(val_dir + '/Dog/' + img), (size, size)).reshape(-1))\n",
    "    val_dogs_labels.append(1)\n",
    "    \n",
    "  val_dogs = np.array(val_dogs)\n",
    "  val_dogs_labels = np.array(val_dogs_labels)\n",
    "  \n",
    "  directory = os.listdir(val_dir + '/Cat')\n",
    "  val_cats = []\n",
    "  val_cats_labels = []\n",
    "  for img in directory:\n",
    "    val_cats.append(cv2.resize(cv2.imread(val_dir + '/Cat/' + img), (size, size)).reshape(-1))\n",
    "    val_cats_labels.append(0)\n",
    "\n",
    "  val_cats = np.array(val_cats)\n",
    "  val_cats_labels = np.array(val_cats_labels)\n",
    "  \n",
    "  \n",
    "  x_train = np.concatenate((train_dogs, train_cats))\n",
    "  y_train = np.concatenate((train_dogs_labels, train_cats_labels))\n",
    "  \n",
    "  x_test = np.concatenate((val_dogs, val_cats))\n",
    "  y_test = np.concatenate((val_dogs_labels, val_cats_labels))\n",
    "  \n",
    "  x_train, y_train = shuffle(x_train, y_train, random_state=123)\n",
    "  x_test, y_test = shuffle(x_test, y_test, random_state=123)\n",
    "  \n",
    "  x_train = x_train.astype('float32') / 255.\n",
    "  x_test = x_test.astype('float32') / 255.\n",
    "  \n",
    "  pca = PCA(n_components=200)\n",
    "  pca.fit(x_train)\n",
    "\n",
    "  x_train = pca.transform(x_train)\n",
    "  x_test = pca.transform(x_test)\n",
    "  \n",
    "  return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e65f78ea6185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mvalidation_set\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdataset_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/valid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgnbayes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-52d1f8d312e3>\u001b[0m in \u001b[0;36mprepare_dataset\u001b[0;34m(train_dir, val_dir, size)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    395\u001b[0m                             'TruncatedSVD for a possible alternative.')\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         X = self._validate_data(X, dtype=[np.float64, np.float32],\n\u001b[0m\u001b[1;32m    398\u001b[0m                                 ensure_2d=True, copy=self.copy)\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    621\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "dataset_path = \"data\"\n",
    "training_set = dataset_path + \"/train\"\n",
    "validation_set =dataset_path + \"/valid\"\n",
    "\n",
    "x_train, y_train, x_test, y_test = prepare_dataset(training_set, validation_set, size=100)\n",
    "\n",
    "gnbayes = GaussianNB()\n",
    "gnbayes.fit(x_train, y_train)\n",
    "score_gnbayes = gnbayes.score(x_test, y_test)\n",
    "print(score_gnbayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
