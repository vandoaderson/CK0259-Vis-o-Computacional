{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 19 – Reconhecimento de Padrões: Introdução\n",
    "\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "Finalmente chegamos no ponto que a “mágica” da Visão Computacional realmente acontece, o reconhecimento de padrões. Entendendo uma imagem como um conjunto de dados (seus pixels), queremos encontrar um padrão nesses dados para reconhecê-lo, isto é, para identificá-lo como algum objeto de interesse. Os algoritmos que fazem esse tratamento são relacionados à Inteligência Artificial e à aprendizagem de máquina.\n",
    "\n",
    "Todos os processos que estudamos até aqui têm o simples intuito de fazer o tratamento dos dados para facilitar a “vida” dos algoritmos de reconhecimento de padrões, pois quando mais informações mais difícil será para identificar os padrões nos dados. Então os tratamentos dados às imagens, como já discutidos várias vezes, retiram toda a informação que não é importante para que identificação de um objeto de interesse ocorra. E, além disso, como ainda assim os dados podem ser muito grandes mesmo depois de todo o pré-processamento feito, ainda podemos utilizar métodos estatísticos, como PCA, para diminuir sua dimensionalidade. Então os métodos e algoritmos que vamos discutir a partir da aula de hoje assumem que os dados já estão todos tratados e limpos, tornando mais fácil a análise de reconhecimento de padrões.\n",
    "\n",
    "O primeiro método a ser discutido será o K-NN (K- Nearest Neighbors / K vizinhos mais próximos), um método de classificação simples que compara dados pela distância (geralmente a euclidiana mesmo) entre eles. A ideia é a seguinte: se temos exemplos de dados pertencentes a algumas classes já classificados previamente, um novo dado que queremos classificar assumirá a mesma classe dos k dados de exemplos mais próximos a ele, onde k é um parâmetro dado. Quando k = 1, o novo dado será classificado pelo algoritmo como sendo da mesma classe do exemplo mais próximo a ele. Se k > 1, assumirá a classe que mais aparecer entre os k exemplos mais próximos. Aos dados de exemplo damos o nome de conjunto de treino.\n",
    "\n",
    "Ou seja, se queremos identificar gatos e cachorros, podemos pegar várias fotos de gatos e várias fotos de cachorro. Fazemos todo o tratamento para que os dados representando as imagens não sejam mais um conjunto gigantesco de pixels, mas sim uma tupla de relativa baixa dimensão de valores, ou seja, vetores relativamente pequenos. A cada um desses vetores, damos a respectiva classe correspondente à imagem original da qual ele foi obtido (gato ou cachorro). Pegamos, então, uma nova imagem que queremos que o algoritmo, por si só, indique se é um cachorro ou um gato. Fazemos exatamente o mesmo pré-processamento da imagem, pegamos o vetor resultante e jogamos para o K-NN, que calculará a distância do vetor da nova imagem para cada um dos outros vetores de exemplo. O K-NN dirá que o novo vetor pertence à classe que mais aparecer entre os K vetores de exemplo mais próximos.\n",
    "\n",
    "Uma leve alteração que se pode fazer no K-NN é, ao invés de calcular a distância do novo dado aos exemplos, calcular a distância à centroide da classe (média das posições dos exemplos da classe). Esse algoritmo recebe o nome de “Protótipo mais próximo”.\n",
    "\n",
    "## 2. Leitura Complementar\n",
    "\n",
    "Livro E – Seção 11.6\n",
    "\n",
    "Livro 1 – Seções 9.1 e 9.2;\n",
    "\n",
    "Livro 2 – Capítulos 11 e 12;\n",
    "\n",
    "Livro 3 - Seções 12.2.1 e 12.2.2\n",
    "\n",
    "## 3. Exercícios\n",
    "\n",
    "1. Faça um classificador de imagens que diferencie cachorros e gatos de acordo com o exemplo citado na nota de aula. Defina um tratamento adequado às imagens com redução de dimensionalidade para que o classificador tenha sucesso. Qual a taxa de acerto do seu classificador?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12501\n",
      "12501\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('data/Cat/')))\n",
    "print(len(os.listdir('data/Dog/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('data/cats-v-dogs')\n",
    "    os.mkdir('data/cats-v-dogs/training')\n",
    "    os.mkdir('data/cats-v-dogs/testing')\n",
    "    os.mkdir('data/cats-v-dogs/training/cats')\n",
    "    os.mkdir('data/cats-v-dogs/training/dogs')\n",
    "    os.mkdir('data/cats-v-dogs/testing/cats')\n",
    "    os.mkdir('data/cats-v-dogs/testing/dogs')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666.jpg is zero length, so ignoring.\n",
      "11702.jpg is zero length, so ignoring.\n",
      "666.jpg is zero length, so ignoring.\n",
      "11702.jpg is zero length, so ignoring.\n"
     ]
    }
   ],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename)\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[-testing_length:]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in testing_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "\n",
    "CAT_SOURCE_DIR = \"data/Cat/\"\n",
    "TRAINING_CATS_DIR = \"data/cats-v-dogs/training/cats/\"\n",
    "TESTING_CATS_DIR = \"data/cats-v-dogs/testing/cats/\"\n",
    "DOG_SOURCE_DIR = \"data/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"data/cats-v-dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"data/cats-v-dogs/testing/dogs/\"\n",
    "\n",
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
    "\n",
    "TRAINING_CATS_DIR = \"data/cats-v-dogs/training/cats/\"\n",
    "TESTING_CATS_DIR = \"data/cats-v-dogs/testing/cats/\"\n",
    "DOG_SOURCE_DIR = \"data/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"data/cats-v-dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"data/cats-v-dogs/testing/dogs/\"\n",
    "\n",
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12378\n",
      "12362\n",
      "2378\n",
      "2362\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('data/cats-v-dogs/training/cats/')))\n",
    "print(len(os.listdir('data/cats-v-dogs/training/dogs/')))\n",
    "print(len(os.listdir('data/cats-v-dogs/testing/cats/')))\n",
    "print(len(os.listdir('data/cats-v-dogs/testing/dogs/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24739 images belonging to 2 classes.\n",
      "Found 4739 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = \"data/cats-v-dogs/training/\"\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=250,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))\n",
    "\n",
    "VALIDATION_DIR = \"data/cats-v-dogs/testing/\"\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size=250,\n",
    "                                                              class_mode='binary',\n",
    "                                                              target_size=(150, 150))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "55/90 [=================>............] - ETA: 5:57 - loss: 0.9268 - acc: 0.5836"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vando/miniconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
      "  warnings.warn(\n",
      "/home/vando/miniconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
      "  warnings.warn(\n",
      "/home/vando/miniconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
      "  warnings.warn(\n",
      "/home/vando/miniconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  warnings.warn(\n",
      "/home/vando/miniconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  warnings.warn(\n",
      "/home/vando/miniconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  warnings.warn(\n",
      "/home/vando/miniconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
      "  warnings.warn(\n",
      "/home/vando/miniconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/90 [===========================>..] - ETA: 1:03 - loss: 0.8344 - acc: 0.5979"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=15, steps_per_epoch=90,\n",
    "                    validation_data=validation_generator, validation_steps=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "acc=history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.figure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
