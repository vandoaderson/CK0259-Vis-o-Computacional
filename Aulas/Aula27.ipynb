{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 27 – Detecção de Faces\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "Para o problema específico de Detecção de Faces, embora possamos utilizar o método mais genérico das Redes Neurais Convolucionais, temos algoritmos mais simples e eficientes para resolvê-lo. Vamos estudar aqui o Viola-Jones (que pode ser utilizado para detecção de objetos em geral, mas tem seu uso principal em faces, pois foi a motivação inicial).\n",
    "\n",
    "A ideia é ter um conjunto de filtros retangulares (“Haar Features”) que guardem em si os padrões típicos de uma face humana (separação dos olhos, linha da boca e dos olhos, etc). Além disso, queremos que essa comparação seja rápida de ser realizada além de flexível (não adianta comparar pixel a pixel, até porque imagens diferentes de rostos vão apresentar variações nos pixels), ou seja, que identifique um “jeitão” e não um conjunto exato de valores. Essa comparação é feita através de um processo chamado de “Tabela de Área Somada”.\n",
    "\n",
    "A grande questão do Viola-Jones é identificar qual o conjunto de Haar Features adequado, já que devem ser consideradas todas as posições das imagens e diferentes tamanhos. O seu processo de treinamento serve, então, para isso. É utilizado um algoritmo de treino chamado AdaBoost.\n",
    "\n",
    "Embora o processo de treinamento seja demorado, o processo de identificação é muito rápido e pode ser utilizado em tempo real sem necessidade de muito poder computacional, ao contrário das Redes Neurais Convolucionais, que geralmente exigem hardwares robustos para funcionarem em tempo real. Estude a Leitura Complementar para detalhes de como funciona o Viola-Jones.\n",
    "\n",
    "## 2. Leitura Complementar\n",
    "\n",
    "https://juliobs.com/Julio_Batista_Silva-TCC-Face_Recognition.pdf\n",
    "\n",
    "## 3. Exercícios\n",
    "\n",
    "A OpenCV tem implementado o algoritmo de Viola-Jones. Além disso, já traz também um modelo treinado que pode ser utilizado para detecção de faces (mas você pode também fazer seu próprio treinamento). Realize o seguinte tutorial para aprender a utilizá-lo:\n",
    " https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--face_cascade FACE_CASCADE]\n",
      "                             [--eyes_cascade EYES_CASCADE] [--camera CAMERA]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/vando/.local/share/jupyter/runtime/kernel-a0d53120-881e-4623-b768-369462ccea90.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "\n",
    "def detectAndDisplay(frame):\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv.equalizeHist(frame_gray)\n",
    "    #-- Detect faces\n",
    "    faces = face_cascade.detectMultiScale(frame_gray)\n",
    "    for (x,y,w,h) in faces:\n",
    "        center = (x + w//2, y + h//2)\n",
    "        frame = cv.ellipse(frame, center, (w//2, h//2), 0, 0, 360, (255, 0, 255), 4)\n",
    "        faceROI = frame_gray[y:y+h,x:x+w]\n",
    "        #-- In each face, detect eyes\n",
    "        eyes = eyes_cascade.detectMultiScale(faceROI)\n",
    "        for (x2,y2,w2,h2) in eyes:\n",
    "            eye_center = (x + x2 + w2//2, y + y2 + h2//2)\n",
    "            radius = int(round((w2 + h2)*0.25))\n",
    "            frame = cv.circle(frame, eye_center, radius, (255, 0, 0 ), 4)\n",
    "    cv.imshow('Capture - Face detection', frame)\n",
    "parser = argparse.ArgumentParser(description='Code for Cascade Classifier tutorial.')\n",
    "parser.add_argument('--face_cascade', help='Path to face cascade.', default='data/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "parser.add_argument('--eyes_cascade', help='Path to eyes cascade.', default='data/haarcascades/haarcascade_eye_tree_eyeglasses.xml')\n",
    "parser.add_argument('--camera', help='Camera divide number.', type=int, default=0)\n",
    "args = parser.parse_args()\n",
    "face_cascade_name = args.face_cascade\n",
    "eyes_cascade_name = args.eyes_cascade\n",
    "face_cascade = cv.CascadeClassifier()\n",
    "eyes_cascade = cv.CascadeClassifier()\n",
    "#-- 1. Load the cascades\n",
    "if not face_cascade.load(cv.samples.findFile(face_cascade_name)):\n",
    "    print('--(!)Error loading face cascade')\n",
    "    exit(0)\n",
    "if not eyes_cascade.load(cv.samples.findFile(eyes_cascade_name)):\n",
    "    print('--(!)Error loading eyes cascade')\n",
    "    exit(0)\n",
    "camera_device = args.camera\n",
    "#-- 2. Read the video stream\n",
    "cap = cv.VideoCapture(camera_device)\n",
    "if not cap.isOpened:\n",
    "    print('--(!)Error opening video capture')\n",
    "    exit(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        print('--(!) No captured frame -- Break!')\n",
    "        break\n",
    "    detectAndDisplay(frame)\n",
    "    if cv.waitKey(10) == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
